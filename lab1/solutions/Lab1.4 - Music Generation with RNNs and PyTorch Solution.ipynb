{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoJsVjtCMunI"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\">\n",
        "    <a target=\"_blank\" href=\"http://inspiredk.org\">\n",
        "    <img align=\"center\" src=\"https://i.ibb.co/Z6HZPSbH/Inspired-K-org-Logo-No-Whitespace-Extra-Small.png\">InspiredK.org Website</a>\n",
        "  </td>\n",
        "  \n",
        "  <td align=\"center\">\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/InspiredK-organization/MITintrotodeeplearning/blob/master/lab1/solutions/Lab1.4 - Music Generation with RNNs and PyTorch Solution.ipynb\">\n",
        "    <img align=\"center\" src=\"https://i.ibb.co/2P3SLwK/colab.png\"/>Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "# Copyright Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUik05YqMyCH"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 MIT Introduction to Deep Learning. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of MIT Introduction\n",
        "# to Deep Learning must reference:\n",
        "#\n",
        "# Â© MIT Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "#\n",
        "# Original lab is adopted from http://introtodeeplearning.com\n",
        "# Lab is edited by http://InspiredK.org"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-97SDET3JG-"
      },
      "source": [
        "# Lab 1: Intro to PyTorch and Music Generation with RNNs\n",
        "\n",
        "# Part 2: Music Generation with RNNs\n",
        "\n",
        "In this portion of the lab, we will explore building a Recurrent Neural Network (RNN) for music generation using PyTorch. We will train a model to learn the patterns in raw sheet music in [ABC notation](https://en.wikipedia.org/wiki/ABC_notation) and then use this model to generate new music."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsvlBQYCrE4I"
      },
      "source": [
        "## 2.1 Dependencies\n",
        "First, let's download the course repository, install dependencies, and import the relevant packages we'll need for this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riVZCVK65QTH"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch and other relevant libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Download and import the MIT Introduction to Deep Learning package\n",
        "!pip install mitdeeplearning --quiet\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import numpy as np # For nparrays\n",
        "import os # For filepath joining\n",
        "import time # Dependency for timing of different tasks\n",
        "import functools # Dependency for functions that output other functions\n",
        "from IPython import display as ipythondisplay # For built-in song playback\n",
        "from tqdm import tqdm # For textual progress bars\n",
        "from scipy.io.wavfile import write # Dependency for creation of downloadable music files\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1 # Dependencies for conversion between text and audio music formats\n",
        "\n",
        "# Check that you are using a GPU. If not, switch runtimes using Runtime > Change Runtime Type > GPU\n",
        "assert torch.cuda.is_available(), \"Please enable GPU from runtime settings\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ajvp0No4qDm"
      },
      "source": [
        "## 2.2 Dataset\n",
        "\n",
        "![Let's Dance!](http://33.media.tumblr.com/3d223954ad0a77f4e98a7b87136aa395/tumblr_nlct5lFVbF1qhu7oio1_500.gif)\n",
        "\n",
        "We've gathered a dataset of thousands of Irish folk songs, represented in the ABC notation. Let's download the dataset and inspect it:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7dFnP5q3Jve"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "songs = mdl.lab1.load_training_data()\n",
        "\n",
        "# Print one of the songs to inspect it in greater detail!\n",
        "example_song = songs[0]\n",
        "print(\"\\nExample song: \")\n",
        "print(example_song)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKF3EHJlCAj2"
      },
      "source": [
        "We can easily convert a song in ABC notation to an audio waveform and play it back. Be patient for this conversion to run, it can take some time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11toYzhEEKDz"
      },
      "outputs": [],
      "source": [
        "# Convert the ABC notation to audio file and listen to it.\n",
        "mdl.lab1.play_song(example_song)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vH24yyquwKQ"
      },
      "source": [
        "One important thing to think about is that this notation of music does not simply contain information on the notes being played, but additionally there is meta information such as the song title, key, and tempo. How does the number of different characters that are present in the text file impact the complexity of the learning problem? This will become important soon, when we generate a numerical representation for the text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlCgQBRVymwR"
      },
      "outputs": [],
      "source": [
        "# Join our list of song strings into a single string containing all songs.\n",
        "songs_joined = \"\\n\\n\".join(songs)\n",
        "\n",
        "# Find all unique characters in the joined string.\n",
        "vocab = sorted(set(songs_joined))\n",
        "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## 2.3 Process the dataset for the learning task\n",
        "\n",
        "Let's take a step back and consider our prediction task. We're trying to train an RNN model to learn patterns in ABC music, and then use this model to generate (i.e., predict) a new piece of music based on this learned information.\n",
        "\n",
        "Breaking this down, what we're really asking the model is: given a character, or a sequence of characters, what is the most probable next character? We'll train the model to perform this task.\n",
        "\n",
        "To achieve this, we will input a sequence of characters to the model, and train the model to predict the output, that is, the following character at each time step. RNNs maintain an internal state that depends on previously seen elements, so information about all characters seen up until a given moment will be taken into account in generating the prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### Vectorize the text\n",
        "\n",
        "Before we begin training our RNN model, we'll need to create a numerical representation of our text-based dataset. To do this, we'll generate two lookup tables: one that maps characters to numbers, and a second that maps numbers back to characters. Recall that we just identified the unique characters present in the text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "outputs": [],
      "source": [
        "### Define numerical representation of text ###\n",
        "\n",
        "# Create a mapping from character to unique index.\n",
        "# For example, to get the index of the character \"d\", we can use `char2idx[\"d\"]`.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "\n",
        "# Create a mapping from indices to characters. This is the inverse of char2idx and allows us to convert back from unique index to the character in our vocabulary.\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfqhkYCymwX"
      },
      "source": [
        "This gives us an integer representation for each character. Observe that the unique characters (i.e., our vocabulary) in the text are mapped as indices from 0 to `len(unique)`. Let's take a peek at this numerical representation of our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYyNlCNXymwY"
      },
      "outputs": [],
      "source": [
        "print('{')\n",
        "for char, _ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char])) # Display each character with its respective index.\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-LnKyu4dczc"
      },
      "outputs": [],
      "source": [
        "### Vectorize the songs string ###\n",
        "\n",
        "'''TODO: Write a function to convert the all songs string to a vectorized (i.e., numeric) representation. Use the appropriate mapping above to convert from vocab characters to the corresponding indices.\n",
        "   NOTE: the output of the `vectorize_string` function should be a np.array with `N` elements, where `N` is the number of characters in the input string\n",
        "'''\n",
        "def vectorize_string(string):\n",
        "  vectorized_output = np.array([char2idx[char] for char in string]) # Use numpy to store vectorized string as nparray.\n",
        "  return vectorized_output\n",
        "\n",
        "# def vectorize_string(string):\n",
        "  # TODO\n",
        "\n",
        "vectorized_songs = vectorize_string(songs_joined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqxpSuZ1w-ub"
      },
      "source": [
        "We can also look at how the first part of the text is mapped to an integer representation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1VKcQHcymwb"
      },
      "outputs": [],
      "source": [
        "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10])) # Visualize string to vectorized string transformation.\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Create training examples and targets\n",
        "\n",
        "Our next step is to actually divide the text into example sequences that we'll use during training. Each input sequence that we feed into our RNN will contain `seq_length` characters from the text. We'll also need to define a target sequence for each input sequence, which will be used in training the RNN to predict the next character. For each input, the corresponding target will contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "To do this, we'll break the text into chunks of `seq_length+1`. Suppose `seq_length` is 4 and our text is \"Hello\". Then, our input sequence is \"Hell\" and the target sequence is \"ello\".\n",
        "\n",
        "The batch method will then let us convert this stream of character indices to sequences of the desired size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF-N8F7BoDRi"
      },
      "outputs": [],
      "source": [
        "### Batch definition to create training examples ###\n",
        "\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  # Get the length of the vectorized song string.\n",
        "  n = vectorized_songs.shape[0] - 1\n",
        "  # Randomly choose `batch_size` starting indices from a range of 0 to `n-seq_length` for the training batch.\n",
        "  idx = np.random.choice(n-seq_length, batch_size)\n",
        "\n",
        "  '''TODO: Construct a list of input sequences for the training batch.'''\n",
        "  input_batch = [vectorized_songs[i : i+seq_length] for i in idx] # Input sequences to the model\n",
        "  # input_batch = # TODO\n",
        "  '''TODO: Construct a list of output sequences for the training batch.'''\n",
        "  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx] # Expected output sequences the model should predict\n",
        "  # output_batch = # TODO\n",
        "\n",
        "  # x_batch and y_batch provide the inputs and expected outputs for network training in the correct shape.\n",
        "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "  return x_batch, y_batch\n",
        "\n",
        "# Perform some tests to make sure the batch function is working properly.\n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args):\n",
        "   print(\"======\\n[FAIL] could not pass tests\")\n",
        "else:\n",
        "   print(\"======\\n[PASS] passed all tests!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_33OHL3b84i0"
      },
      "source": [
        "For each of these vectors, each index is processed at a single time step. So, for the input at time step 0, the model receives the index for the first character in the sequence, and tries to predict the index of the next character. At the next timestep, it does the same thing, but the RNN considers the information from the previous step, i.e., its updated state, in addition to the current input.\n",
        "\n",
        "We can make this concrete by taking a look at how this works over the first several characters in our text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eBu9WZG84i0"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1) # Create a test batch with 5 characters.\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(x_batch[0], y_batch[0])): # Visualize each character in the x and y batches.\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(str(idx2char[input_idx]))))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(str(idx2char[target_idx]))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## 2.4 The Recurrent Neural Network (RNN) model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "Now we're ready to define and train an RNN model on our ABC music dataset, and then use that trained model to generate a new song. We'll train our RNN using batches of song snippets from our dataset, which we generated in the previous section.\n",
        "\n",
        "The model is based off the LSTM architecture, where we use a state vector to maintain information about the temporal relationships between consecutive characters. The final output of the LSTM is then fed into a fully connected linear [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) layer where we'll output a softmax over each character in the vocabulary, and then sample from this distribution to predict the next character.\n",
        "\n",
        "As we introduced in the first portion of this lab, we'll be using PyTorch's [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) to define the model. Three components are used to define the model:\n",
        "\n",
        "* [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html): This is the input layer, consisting of a trainable lookup table that maps the numbers of each character to a vector with `embedding_dim` dimensions.\n",
        "* [`nn.LSTM`](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html): Our LSTM network, with size `hidden_size`.\n",
        "* [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html): The output layer, with `vocab_size` outputs.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2019/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/>\n",
        "\n",
        "\n",
        "\n",
        "<!--\n",
        "Now we're ready to define and train a RNN model on our ABC music dataset, and then use that trained model to generate a new song. We'll train our RNN using batches of song snippets from our dataset, which we generated in the previous section.\n",
        "\n",
        "The model is based off the LSTM architecture, where we use a state vector to maintain information about the temporal relationships between consecutive characters. The final output of the LSTM is then fed into a fully connected [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer where we'll output a softmax over each character in the vocabulary, and then sample from this distribution to predict the next character.\n",
        "\n",
        "As we introduced in the first portion of this lab, we'll be using the Keras API, specifically, [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential), to define the model. Three layers are used to define the model:\n",
        "\n",
        "* [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding): This is the input layer, consisting of a trainable lookup table that maps the numbers of each character to a vector with `embedding_dim` dimensions.\n",
        "* [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): Our LSTM network, with size `units=rnn_units`.\n",
        "* [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): The output layer, with `vocab_size` outputs.\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2019/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlaOqndqBmJo"
      },
      "source": [
        "### Define the RNN model\n",
        "\n",
        "Let's define our model as an `nn.Module`. Fill in the `TODOs` to define the RNN model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DsWzojvkbc7"
      },
      "outputs": [],
      "source": [
        "### Defining the RNN Model ###\n",
        "\n",
        "'''TODO: Add LSTM and Linear layers to define the RNN model using nn.Module'''\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Layer 1: The embedding layer to transform indices into dense vectors of a fixed embedding size.\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Layer 2: The LSTM layer with hidden_size `hidden_size`. Note: the number of layers defaults to 1.\n",
        "        # TODO: Use the nn.LSTM() module from PyTorch.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True) # Long short-term memory (LSTM) is good for tasks that require a long context memory.\n",
        "        # self.lstm = nn.LSTM('''TODO''')\n",
        "\n",
        "        # Layer 3: The linear (fully-connected) layer that transforms the LSTM output into the vocabulary size.\n",
        "        # TODO: Add the Linear layer.\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "        # self.fc = nn.Linear('''TODO''')\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        # Initialize the hidden state and cell state with all zeros.\n",
        "        return (torch.zeros(1, batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(1, batch_size, self.hidden_size).to(device))\n",
        "\n",
        "    # Pass an input of x all the way through the model to get a probability distribution output.\n",
        "    def forward(self, x, state=None, return_state=False):\n",
        "        x = self.embedding(x) # Embed the input using our embedding layer.\n",
        "\n",
        "        if state is None: # If the hidden state has not been created yet,\n",
        "            state = self.init_hidden(x.size(0), x.device) # Then initialize it with our previous function.\n",
        "        out, state = self.lstm(x, state) # Use the LSTM to update the state and get an output.\n",
        "\n",
        "        out = self.fc(out) # Get the final output from the linear layer.\n",
        "        return out if not return_state else (out, state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbWU4dMJmMvq"
      },
      "source": [
        "The time has come! Let's instantiate the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtCrdfzEI2N0"
      },
      "outputs": [],
      "source": [
        "# Build a simple model with default hyperparameters. You will get the chance to change these later.\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "hidden_size = 1024\n",
        "batch_size = 32\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Make sure our model is using a GPU.\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_size).to(device) # Initialize the model using the GPU.\n",
        "\n",
        "# Print out a summary of the model.\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "### Test out the RNN model\n",
        "\n",
        "It's always a good idea to run a few simple checks on our model to see that it behaves as expected.  \n",
        "\n",
        "We can quickly check the layers in the model, the shape of the output of each of the layers, the batch size, and the dimensionality of the output. Note that the model can be run on inputs of any length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-_70kKAPrPU"
      },
      "outputs": [],
      "source": [
        "# Test the model with some sample data\n",
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32) # Get a batch with 32 sequences of 100 characters each for a test prediction.\n",
        "# Put the input on our GPU to be passed to the model.\n",
        "x = torch.tensor(x).to(device)\n",
        "y = torch.tensor(y).to(device)\n",
        "\n",
        "pred = model(x) # Pass the input batch into the model for prediction.\n",
        "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
        "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT1HvFVUGpoE"
      },
      "source": [
        "### Predictions from the untrained model\n",
        "\n",
        "Let's take a look at what our untrained model is predicting.\n",
        "\n",
        "To get actual predictions from the model, we sample from the output distribution, which is defined by a torch.softmax over our character vocabulary. This will give us actual character indices. This means we are using a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) to sample over the example prediction. This gives a prediction of the next character (specifically its index) at each timestep. [`torch.multinomial`](https://pytorch.org/docs/stable/generated/torch.multinomial.html#torch.multinomial) samples over a categorical distribution to generate predictions.\n",
        "\n",
        "Note here that we sample from this probability distribution, as opposed to simply taking the `argmax`, which can cause the model to get stuck in a repetitive loop.\n",
        "\n",
        "Let's try this sampling out for the first example in the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "outputs": [],
      "source": [
        "sampled_indices = torch.multinomial(torch.softmax(pred[0], dim=-1), num_samples=1)\n",
        "sampled_indices = sampled_indices.squeeze(-1).cpu().numpy()\n",
        "sampled_indices # Use a probability distribution to find the characters with the highest prediction probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "We can now decode these to see the text predicted by the untrained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWcFwPwLSo05"
      },
      "outputs": [],
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0].cpu()]))) # An example input of the first sequence from our batch of 32.\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices]))) # The predicted output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEHHcRasIDm9"
      },
      "source": [
        "As you can see, the text predicted by the untrained model is pretty nonsensical! How can we do better? Well, we can train the network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## 2.5 Training the model: loss and training operations\n",
        "\n",
        "Now it's time to train the model!\n",
        "\n",
        "At this point, we can think of our next character prediction problem as a standard classification problem. Given the previous state of the RNN, as well as the input at a given time step, we want to predict the class of the next character -- that is, to actually predict the next character.\n",
        "\n",
        "To train our model on this classification task, we can use a form of the `crossentropy` loss (i.e., negative log likelihood loss). Specifically, we will use PyTorch's [`CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), as it combines the application of a log-softmax ([`LogSoftmax`](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax)) and negative log-likelihood ([`NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss) in a single class and accepts integer targets for categorical classification tasks. We will want to compute the loss using the true targets -- the `labels` -- and the predicted targets -- the `logits`.\n",
        "\n",
        "Let's define a function to compute the loss, and then use that function to compute the loss using our example predictions from the untrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HrXTACTdzY-"
      },
      "outputs": [],
      "source": [
        "### Defining the loss function ###\n",
        "\n",
        "'''TODO: Define the compute_loss function to compute and return the loss between the true labels and predictions (logits). '''\n",
        "cross_entropy = nn.CrossEntropyLoss() # This type of loss is highly efficient and simple yet also accurate, making it the best option for our task.\n",
        "def compute_loss(labels, logits):\n",
        "    \"\"\"Inputs:\n",
        "    * (batch_size, sequence_length) - labels\n",
        "    * (batch_size, sequence_length, vocab_size) - logits\n",
        "\n",
        "    Output:\n",
        "    * scalar cross entropy loss over the batch and sequence length - loss\n",
        "    \"\"\"\n",
        "\n",
        "    # Put the labels into batches so that their shape is (B * L).\n",
        "    batched_labels = labels.view(-1)\n",
        "\n",
        "    # Put the logits into batches so that their shape is (B * L, V).\n",
        "    batched_logits = logits.view(-1, logits.size(-1))\n",
        "\n",
        "    '''TODO: Compute the cross-entropy loss using the batched next characters and predictions. Hint: It is define directly above the function.'''\n",
        "    loss = cross_entropy(batched_logits, batched_labels)\n",
        "    # loss = # TODO\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuGUJB0ZT_Uo"
      },
      "outputs": [],
      "source": [
        "# Compute the loss on the predictions from the untrained model.\n",
        "\n",
        "'''TODO: Compute the loss using the true next characters from the example batch\n",
        "    and the predictions from the untrained model we created before the loss function.'''\n",
        "example_batch_loss = compute_loss(y, pred)\n",
        "# example_batch_loss = compute_loss('''TODO''', '''TODO''') # TODO\n",
        "\n",
        "print(f\"Prediction shape: {pred.shape} # (batch_size, sequence_length, vocab_size)\")\n",
        "print(f\"scalar_loss:      {example_batch_loss.mean().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Seh7e6eRqd7"
      },
      "source": [
        "Let's start by defining some hyperparameters for training the model. To start, we have provided some reasonable values for some of the parameters. It is up to you to use what we've learned in class to help optimize the parameter selection here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQWUUhKotkAY"
      },
      "outputs": [],
      "source": [
        "### Hyperparameter setting and optimization ###\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Model parameters:\n",
        "params = dict(\n",
        "  num_training_iterations = 5000,  # Increase this to train longer\n",
        "  batch_size = 16,  # Experiment between 1 and 64\n",
        "  seq_length = 100,  # Experiment between 50 and 500\n",
        "  learning_rate = 1e-4,  # Experiment between 1e-5 and 1e-1\n",
        "  embedding_dim = 256,\n",
        "  rnn_units = 1024,  # Experiment between 1 and 2048\n",
        ")\n",
        "\n",
        "# Create a file to store our model's weights.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt.weights.h5\")\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cu11p1MKYZd"
      },
      "source": [
        "Now, we are ready to define our training operation -- the optimizer and duration of training -- and use this function to train the model. You will experiment with the choice of optimizer and the duration for which you train your models, and see how these changes affect the network's output. Some optimizers you may like to try are [`Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) and [`Adagrad`](https://pytorch.org/docs/stable/generated/torch.optim.Adagrad.html).\n",
        "\n",
        "First, we will instantiate a new model and an optimizer, and ready them for training. Then, we will use [`loss.backward()`](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html), enabled by PyTorch's [autograd](https://pytorch.org/docs/stable/generated/torch.autograd.grad.html) method, to perform the backpropagation. Finally, to update the model's parameters based on the computed gradients, we will utake a step with the optimizer, using [`optimizer.step()`](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html).\n",
        "\n",
        "We will also generate a print-out of the model's progress through training, which will help us easily visualize whether or not we are minimizing the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F31vzJ_u66cb"
      },
      "outputs": [],
      "source": [
        "### Define optimizer and training operation ###\n",
        "\n",
        "'''TODO: instantiate a new LSTMModel model for training using the hyperparameters\n",
        "    created above.'''\n",
        "model = LSTMModel(vocab_size, params[\"embedding_dim\"], params[\"rnn_units\"])\n",
        "# model = LSTMModel('''TODO: arguments''')\n",
        "\n",
        "# Move the model to the GPU.\n",
        "model.to(device)\n",
        "\n",
        "'''TODO: Create an optimizer with the set learning rate.\n",
        "  The PyTorch website has a list of all the optimizers available, try some others to see what works best.\n",
        "  https://pytorch.org/docs/stable/optim.html\n",
        "  Try using the Adam optimizer to start.'''\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
        "# optimizer = # TODO\n",
        "\n",
        "def train_step(x, y):\n",
        "  # Set the model's mode to the training stage.\n",
        "  model.train()\n",
        "\n",
        "  # Reset all gradients for every training step to ensure nothing interferes with our current step.\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  '''TODO: Feed the provided input into the model and generate predictions'''\n",
        "  y_hat = model(x) # TODO\n",
        "  # y_hat = model('''TODO''')\n",
        "\n",
        "  '''TODO: Compute the loss based on these predictions.'''\n",
        "  loss = compute_loss(y, y_hat) # TODO\n",
        "  # loss = compute_loss('''TODO''', '''TODO''')\n",
        "\n",
        "  '''TODO: Complete the gradient computation and update the model using the optimizer and the gradient.\n",
        "    The steps to do this are:\n",
        "      1. Backpropagating the loss with .backward()\n",
        "      2. Update the model parameters using the optimizer with .step()\n",
        "  '''\n",
        "  loss.backward() # TODO\n",
        "  optimizer.step() # TODO\n",
        "\n",
        "  return loss\n",
        "\n",
        "##################\n",
        "# Begin training!#\n",
        "##################\n",
        "\n",
        "history = [] # Create a list to store all losses for graphing.\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss') # Initialize the graph that will continuously update for every new loss.\n",
        "\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # Clear any previous progress bars if they exist.\n",
        "for iter in tqdm(range(params[\"num_training_iterations\"])): # Create a new progress bar to track training progress.\n",
        "\n",
        "    # Grab a batch and propagate it through the network.\n",
        "    x_batch, y_batch = get_batch(vectorized_songs, params[\"seq_length\"], params[\"batch_size\"])\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors to be compatible with the model.\n",
        "    x_batch = torch.tensor(x_batch).to(device)\n",
        "    y_batch = torch.tensor(y_batch).to(device)\n",
        "\n",
        "    loss = train_step(x_batch, y_batch) # Use the batch to optimize the weights using the previous function.\n",
        "\n",
        "    # Update the progress bar and also visualize within notebook.\n",
        "    history.append(loss.item()) # Add the computed loss to the graphing list.\n",
        "    plotter.plot(history) # Plot the new graph for the new loss.\n",
        "\n",
        "    # Update the model with the changed weights!\n",
        "    if iter % 100 == 0:\n",
        "        torch.save(model.state_dict(), checkpoint_prefix) # Every 100 training iterations, save the weights.\n",
        "                                              # If the training is interrupted, the best weights will be safe and can be used for music generation.\n",
        "\n",
        "# Save the trained model and the weights.\n",
        "torch.save(model.state_dict(), checkpoint_prefix) # If training is not interrupted, save the final weights. They will be used for music generation later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## 2.6 Generate music using the RNN model\n",
        "\n",
        "Now, we can use our trained RNN model to generate some music! When generating music, we'll have to feed the model some sort of seed to get it started (because it can't predict anything without something to start with!).\n",
        "\n",
        "Once we have a generated seed, we can then iteratively predict each successive character (remember, we are using the ABC representation for our music) using our trained RNN. More specifically, recall that our RNN outputs a `softmax` over possible successive characters. For inference, we iteratively sample from these distributions, and then use our samples to encode a generated song in the ABC format.\n",
        "\n",
        "Then, all we have to do is write it to a file and listen!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "### The prediction procedure\n",
        "\n",
        "Now, we're ready to write the code to generate text in the ABC music format:\n",
        "\n",
        "* Initialize a \"seed\" start string and the RNN state, and set the number of characters we want to generate.\n",
        "\n",
        "* Use the start string and the RNN state to obtain the probability distribution over the next predicted character.\n",
        "\n",
        "* Sample from multinomial distribution to calculate the index of the predicted character. This predicted character is then used as the next input to the model.\n",
        "\n",
        "* At each time step, the updated RNN state is fed back into the model, so that it now has more context in making the next prediction. After predicting the next character, the updated RNN states are again fed back into the model, which is how it learns sequence dependencies in the data, as it gets more information from the previous predictions.\n",
        "\n",
        "![LSTM inference](https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2019/lab1/img/lstm_inference.png)\n",
        "\n",
        "Complete and experiment with this code block (as well as some of the aspects of network definition and training!), and see how the model performs. How do songs generated after training with a small number of epochs compare to those generated after a longer duration of training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "outputs": [],
      "source": [
        "### Prediction of a generated song ###\n",
        "\n",
        "def generate_text(model, start_string, generation_length=1000):\n",
        "  # Evaluation step (generating ABC text using the learned RNN model)\n",
        "\n",
        "  '''TODO: Convert the start string to numbers (vectorize)'''\n",
        "  input_eval = [char2idx[s] for s in start_string] # Vectorize the given start string.\n",
        "  # input_eval = ['''TODO''']\n",
        "  input_eval = torch.tensor([input_eval], dtype=torch.long).to(device) # Change input shape for compatibility with the generative model.\n",
        "\n",
        "  text_generated = [] # Create an empty list to store all generate characters.\n",
        "\n",
        "  state = model.init_hidden(input_eval.size(0), device) # Makes sure that previous LSTM predictions don't interfere with this one.\n",
        "  tqdm._instances.clear() # Clear any previous progress bars.\n",
        "\n",
        "  for i in tqdm(range(generation_length)): # Create a new progress bar to track generation progress.\n",
        "    '''TODO: Evaluate the inputs and generate the next character predictions.'''\n",
        "    predictions, hidden_state = model(input_eval, state, return_state=True) # Get model predictions based on the initial input string.\n",
        "    # predictions, hidden_state = model('''TODO''', '''TODO''', return_state=True)\n",
        "\n",
        "    predictions = predictions.squeeze(0) # Change output shape for compatibility with output.\n",
        "\n",
        "    '''TODO: Use a multinomial distribution to sample.'''\n",
        "    input_eval = torch.multinomial(torch.softmax(predictions, dim=-1), num_samples=1) # Similar to before, use a probability distribution to find the characters with the highest prediction probability.\n",
        "    # input_eval = torch.multinomial(torch.softmax('''TODO''', dim=-1), num_samples=1)\n",
        "\n",
        "    '''TODO: Add the predicted character to the generated text.'''\n",
        "    # Hint: Consider what format the prediction is in vs. the output.\n",
        "    text_generated.append(idx2char[input_eval].item()) # Also add the predicted character to the generation list.\n",
        "    # text_generated.append('''TODO''')\n",
        "\n",
        "  return (start_string + ''.join(text_generated))  # Once generation is finished, output the entire generated text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktovv0RFhrkn"
      },
      "outputs": [],
      "source": [
        "'''TODO: Use the model and the function defined above to generate ABC format text of length 1000!\n",
        "    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\n",
        "generated_text = generate_text(model, start_string=\"X\", generation_length=1000) # Generate 1000 characters with a start string of \"X.\"\n",
        "                                                                                # \"X\" is usually at the start of our music files, making it a good choice.\n",
        "# generated_text = generate_text('''TODO''', start_string=\"X\", generation_length=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM2Uma_-yVIq"
      },
      "source": [
        "### Play back the generated music!\n",
        "\n",
        "We can now call a function to convert the ABC format text to an audio file, and then play that back to check out our generated music! Try training longer if the resulting song is not long enough, or re-generating the song!\n",
        "\n",
        "We will save the song to the Files area in Google Colab -- you will be able to find your songs in the left sidebar by clicking on the folder icon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrOtG64bfLto"
      },
      "outputs": [],
      "source": [
        "### Play back generated songs ###\n",
        "\n",
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text) # Separate the generated text into individual songs.\n",
        "\n",
        "for i, song in enumerate(generated_songs):\n",
        "  waveform = mdl.lab1.play_song(song) # Convert the song from text format to an audio file.\n",
        "\n",
        "  if waveform: # If the song is in the correct format, play it.\n",
        "    print(\"Generated song\", i) # Identify each song with a number.\n",
        "    ipythondisplay.display(waveform) # Display the audio file in the output to be played without the need for downloading.\n",
        "\n",
        "    # Save the song to Google Colab's files if you would like to download your songs.\n",
        "    numeric_data = np.frombuffer(waveform.data, dtype=np.int16)\n",
        "    wav_file_path = f\"output_{i}.wav\"\n",
        "    write(wav_file_path, 88200, numeric_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgVvcrYmSKGG"
      },
      "source": [
        "## 2.7 Experiment and try to make the best songs!\n",
        "\n",
        "Congrats on making your first sequence model in PyTorch! It's a pretty big accomplishment, and hopefully you have some sweet tunes to show for it.\n",
        "\n",
        "Consider how you may improve your model and what seems to be most important in terms of performance. Here are some ideas to get you started:\n",
        "\n",
        "*  How does the number of training epochs affect the performance?\n",
        "*  What if you alter or augment the dataset?\n",
        "*  Does the choice of start string significantly affect the result?\n",
        "\n",
        "Have fun and happy listening!\n",
        "\n",
        "![Let's Dance!](http://33.media.tumblr.com/3d223954ad0a77f4e98a7b87136aa395/tumblr_nlct5lFVbF1qhu7oio1_500.gif)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uoJsVjtCMunI"
      ],
      "name": "Lab1.4 - Music Generation with RNNs and PyTorch Solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
